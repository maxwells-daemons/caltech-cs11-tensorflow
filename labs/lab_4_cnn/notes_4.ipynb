{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Convolutional Neural Networks\n",
    "When your input is shaped \"like a grid\" (think of audio as a 1-D grid, images as a 2-D grid, 3-D scans, ...), there's a good chance it has _local structure_: points closer in the grid are more related to each other than they are to points further away.\n",
    "In images, for example, small patterns of nearby pixels can form simple patterns like edges or corners, or more complex patterns like faces.\n",
    "Pixels in the upper-left of an image are almost unrelated to pixels in the bottom-right corner, except that they're part of the same image.\n",
    "\n",
    "Another observation is that these local patterns can show up anywhere in the image.\n",
    "If you're trying to detect faces, it doesn't really matter where they are in the input.\n",
    "This suggests that we should use the same structure to detect a given pattern everywhere in an image.\n",
    "\n",
    "Convolutions let us take advantage of both of these observations.\n",
    "Instead of connecting every part of the input to every part of the output in the same way, as dense layers do, convolutional layers learn small filters which recognize local patterns and \"slide\" them around the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions\n",
    "The heart of convolutional layers is an operation called \"discrete convolution\" which formalizes how we \"slide filters around the grid.\"\n",
    "\n",
    "## What does \"like a grid\" mean?\n",
    "What this really means is that the input data has some kind of _ordering_ along at least one of its axes.\n",
    "128x128-pixel color images will be represented by tensors of shape [128, 128, 3] -- the first two axes refer to the pixel, and the third picks an RGB **channel**.\n",
    "The channel axis (also sometimes called the depth axis) is not ordered, since red is no closer to green than it is to blue.\n",
    "But the first two axes are ordered: pixel (1, 1) is closer to pixel (1, 2) than it is to (1, 3) or (3, 3).\n",
    "\n",
    "Convolutional layers are designed to take advantage of this ordering, by assuming that points that are close on ordered axes are more related than points that are further away.\n",
    "Convolutions will only act on the ordered axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels\n",
    "Instead of a set of dense weights, convolutional layers learn a set of **kernels**, which are formatted like small patches of grid.\n",
    "In 1-D, they're 1-dimensional grid segments, in 2-D they're little squares, and in 3-D they're volumes.\n",
    "\n",
    "To compute the **activation** of a kernel in a particular location in the grid, place the kernel centered there, then compute the dot product of the kernel and the input by multiplying elements that line up and summing the results.\n",
    "\n",
    "The full result of **convolving** a kernel over an input is the set of activations produced by \"sliding\" the kernel to all locations on the input, resulting in a grid shaped like the input.\n",
    "This is often called an **activation map**.\n",
    "\n",
    "One really important thing to notice here is that _convolution preserves order_.\n",
    "When you convolve a kernel over an image, the upper-left of the activation map corresponds to the upper-left of the image.\n",
    "This means that convolutional layers can _preserve local structure_ even as you apply multiple convolutional layers in sequence.\n",
    "Compare this with dense layers, which connect every output to every input and so lose all ordering information.\n",
    "\n",
    "Another important property is that convolutions find small local patterns.\n",
    "You can think of the kernel as a \"template\".\n",
    "Its activation on a patch of image indicates how well that image patch matches the template: high positive values mean they have high \"similarity\" (note that the dot product is not actually normalized), high negative values mean they have similar structure but opposite sign, and values near zero mean that the kernel doesn't structurally match the input there.\n",
    "These \"templates\" are applied everywhere on the input, able to match the same pattern (e.g. an edge or a face) again and again.\n",
    "\n",
    "### 1D\n",
    "![1-D convolution](https://files.realpython.com/media/njanakiev-1d-convolution.d7afddde2776.png)\n",
    "(Image source: [Deep Learning with Python](https://realpython.com/asins/1617294438/))\n",
    "\n",
    "### 2D\n",
    "![2-D convolution gif](https://cdn-images-1.medium.com/max/1440/1*Zx-ZMLKab7VOCQTxdZ1OAw.gif)\n",
    "\n",
    "In this animation, the input image is the blue grid on the left, the output is the teal grid on the right, and the kernel is the square grid of weights\n",
    "$$\\begin{bmatrix}0 & 1 & 2 \\\\ 2 & 2 & 0 \\\\ 0 & 1 & 2 \\end{bmatrix}$$\n",
    "The activation at a particular location is shown by shading where the kernel is on the input and the resulting space in the output.\n",
    "\n",
    "(Image source: [\"A guide to convolution arithmetic for deep learning\"](https://arxiv.org/abs/1603.07285))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters\n",
    "Kernels act only on a single channel, and produce a single channel.\n",
    "When dealing with multi-channel data (like RGB images, or multi-band satellite imagery), the output of a convolutional layer should be based on all of the channels together.\n",
    "So, instead of using a kernel, we use a **filter**: a collection of kernels, one for each channel in the input's depth axis.\n",
    "\n",
    "![filter](https://cdn-images-1.medium.com/max/1080/1*lRpx5pTrVewFTD8YXjhIKA.png)\n",
    "\n",
    "(Image source: [\"Intuitively understanding convolutions for deep learning\"](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1))\n",
    "\n",
    "The activation of a filter at a point on an image is the sum of the activations of each of its kernels, applied to one of the channels.\n",
    "So, each filter takes in a grid of multiple channels and produces a new grid of a single channel (the activation map).\n",
    "\n",
    "To increase the capacity of a convolutional layer, we use multiple filters in parallel, analogous to the \"width\" or \"number of units\" hyperparameter for dense layers.\n",
    "The activation maps of each filter are concatenated.\n",
    "\n",
    "So, the first layer of a convolutional neural network (CNN) that operates on 128x128-pixel RGB and uses 64 5x5 filters has the following shapes:\n",
    " - Input images have shape [128, 128, 3] (pixel, pixel, channel)\n",
    " - Each kernel has shape [5, 5] (pixel, pixel)\n",
    " - Each filter has shape [5, 5, 3] (pixel, pixel, channel)\n",
    " - Each filter's activation map has shape [128, 128] (pixel, pixel)\n",
    " - The output of the layer has shape [128, 128, 64] (pixel, pixel, channel)\n",
    "(assuming that the layer is padded so the activation maps are still 128x128 pixels)\n",
    "\n",
    "Note: the next layer's filters would have shape [5, 5, 64] (assuming 5x5 convolutions).\n",
    "Examples typically come in batches, so you can think of each shape also having a batch axis.\n",
    "With a batch size of 8, for example, input image batches would have a shape of [8, 128, 128, 3].\n",
    "\n",
    "For a good visual summary, check out this diagram from [\"A guide to convolution arithmetic for deep learning\"](https://arxiv.org/abs/1603.07285): \n",
    "![multi-channel convolution](./images/convolution_channels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks\n",
    "Since the outputs of a convolutional layer preserve ordering along ordered axes, and multiple filters result in the output having channels, _the outputs have the same format as the inputs_.\n",
    "In this case, an input 128x128 image with 3 channels is turned into an output 128x128 image with 64 channels.\n",
    "This means that we can apply another convolutional layer to the output in order to build deep convolutional neural networks!\n",
    "\n",
    "Much like when we stack dense layers, early convolutional layers capture simple patterns (like edges, corners, and textures) and later convolutional layers use patterns in those patterns to make higher-level features (like object parts and objects).\n",
    "\n",
    "![feature hierarchy](./images/feature_hierarchy.png)\n",
    "\n",
    "(Image source: skymind.ai, [\"A Beginner's Guide to Neural Networks and Deep Learning\"](https://skymind.ai/wiki/neural-network))\n",
    "\n",
    "![feature hierarchy 2](http://teleported.in/post_imgs/11-zeiler-fertus.jpg)\n",
    "(Image source: [\"Visualizing and Understanding Convolutional Networks\"](https://arxiv.org/abs/1311.2901))\n",
    "\n",
    "This is great for the \"feature extraction\" part of a neural network, but how do we use the final activation maps to do classification or regression?\n",
    "Often, the last activation map is \"flattened\" into a vector, then fed into a dense layer.\n",
    "Usually one or two dense layers, followed by an output layer, are sufficient.\n",
    "\n",
    "For example, if the last convolutional layer of a model is of shape [10, 10, 16], it will be flattened to a vector of shape [10 * 10 * 16] = [1600].\n",
    "Then, every unit in the first dense layer will have 1600 inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting convolutional layers\n",
    "Like dense layers, convolutional layers have lots of interpretations.\n",
    "\n",
    "## Learning filters\n",
    "The idea of convolving filters over images didn't originate with machine learning.\n",
    "In signal processing and image processing, hand-designed kernels are common.\n",
    "For example, hand-designed kernels exist for smoothing, sharpening, and edge detection on images.\n",
    "\n",
    "![filters](./images/filters.png)\n",
    "\n",
    "(Image source: https://en.wikipedia.org/wiki/Kernel_(image_processing))\n",
    "\n",
    "Convolutional layers can be interpreted as learning filters of this sort that produce useful features when convolved over images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A variant of dense layers\n",
    "Mathematically, convolutional layers are equivalent to dense layers with two very important constraints:\n",
    " - Many of the values are set to zero. This corresponds to the property that the pattern a kernel matches is local: it's based on a small number of adjacent inputs, and the weights connecting those inputs to other (non-local) outputs are zero.\n",
    " - The same weights are repeated many times in a fixed pattern. This corresponds to the property that the same kernel is applied many times on the same input.\n",
    "\n",
    "For instance, a dense layer acting on a 4x4 image to produce a 2x2 image requires (4\\*4) \\* (2\\*2) = 64 weights, arranged in a 4x16 matrix (taking in a 16-vector and producing a 4-vector through affine transformation):\n",
    "![dense layer](https://cdn-images-1.medium.com/max/1800/1*Nq-Za2-OzW8J5n7Tu7QIWw.png)\n",
    "\n",
    "However, a 3x3 kernel $K$ acting on this image just requires 3\\*3 = 9 weights.\n",
    "\n",
    "$$K = \\begin{bmatrix}k_{1,1} & k_{1,2} & k_{1 ,3} \\\\ k_{2,1} & k_{2,2} & k_{2 ,3} \\\\ k_{3,1} & k_{3,2} & k_{3 ,3} \\end{bmatrix}$$\n",
    "\n",
    "Convolving this kernel with the input can be represented as multiplying by a specific 4x16 matrix:\n",
    "![convolution as a dense layer](https://cdn-images-1.medium.com/max/1800/1*cr0IabpKu4zIyvDgCTQ64A.png)\n",
    "\n",
    "(Source of images: [\"Intuitively Understanding Convolutions for Deep Learning\"](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1))\n",
    "\n",
    "These properties lead to the interpretation of convolutions as dense layers with three very strong priors:\n",
    " - Patterns are purely local. This is also called the property of having \"sparse interactions.\" This vastly reduces the number of parameters a layer has, making convolutional layers much faster to run and train, as well as being vastly more statistically efficient (easy to learn well with the available data).\n",
    " - Parameters are shared throughout the layer (called \"weight sharing\" or \"weight tying\"). This is the prior that the same pattern can appear anywhere in an input.\n",
    " - The activation map should be **equivariant** with respect to translation. That means that if something is shifted in an image, the resulting activation is shifted by the same amount in the activation map. \n",
    "\n",
    "These priors work extremely well in practice on images and other kinds of grid-shaped data, including many kinds of time-series data (such as speech waveforms)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules / functions\n",
    "One interpretation of the value of weight sharing is that it corresponds to using the same neuron or group of neurons many places in the input like a programmer might write a function and use it many times in a program.\n",
    "\n",
    "From this perspective, forcing the network to apply the same group of neurons multiple times forces it to learn representations that are useful in many ways, leading to robust representation.\n",
    "If the prior that these \"functions\" are a good fit for the input is accurate, then learning one function and applying it many times is much easier than learning the function many times, once in each place it could be applied.\n",
    "In practice this seems to be the case.\n",
    "\n",
    "![modular conv net](https://colah.github.io/posts/2014-07-Conv-Nets-Modular/img/Conv-9-Conv2Conv2.png)\n",
    "\n",
    "In the image above, taken from Chris Olah's [\"Conv Nets: A Modular Perspective\"](https://colah.github.io/posts/2014-07-Conv-Nets-Modular/), the network:\n",
    " 1. Applies a learned function, A, to every point on the input\n",
    " 2. Applies a second learned function, B, to the outputs of A\n",
    " 3. Feeds the outputs of B into a dense layer F, which produces the output.\n",
    "In this view, F is like a large \"block of code\", kind of like a `main()` function, that chooses how to apply the functions A and B by deciding which of their activations on the input are important and how to use them.\n",
    "\n",
    "If you'd like to read more about this view, check out the blog post linked above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output size, padding, receptive field, and stride\n",
    "Note: throughout this box, the animations used have the input on the bottom (blue) and the output on top (teal).\n",
    "Source: https://github.com/vdumoulin/conv_arithmetic.\n",
    "\n",
    "## Output size\n",
    "Because you can't center the kernel on the edge of the image, the output of a convolution will be slightly smaller than the input:\n",
    "![convolution without padding](https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_no_strides.gif)\n",
    "This effect gets more significant with larger kernel sizes.\n",
    "\n",
    "## Padding\n",
    "However, it's common in many cases to pad the edges of the input so that the output and input have the same dimensions:\n",
    "\n",
    "![same padding](https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/same_padding_no_strides.gif)\n",
    "\n",
    "This is called \"same padding,\" and sometimes not padding the input is called \"valid padding\" or \"valid convolution\" (because you only place the kernel on the input where it's \"valid\").\n",
    "Usually the input is padded with zeroes (this is the only kind of padding Keras supports), though [there are some issues with this](https://twitter.com/karpathy/status/720622989289644033?lang=en).\n",
    "Sometimes \"border reflection\" is used instead.\n",
    "Zero-padding usually works fine in practice, though.\n",
    "\n",
    "Same padding is useful for a few reasons:\n",
    " - It enables deeper networks by preventing shrinkage. Even losing 2 pixels at the boundary per layer can be a big deal for deep networks operating on low-resolution inputs.\n",
    " - It prevents the model from losing information at the edges.\n",
    " - It enables more advanced architectures like Inception to use multiple different sizes of kernels within the same layer, since their outputs will all have the same size.\n",
    "\n",
    "## Receptive field\n",
    "An important quantity to think about when designing convolutional networks is **receptive field**.\n",
    "The receptive field of a pixel in an activation map is the set of pixels in the input image that contributed to making that activation.\n",
    "For example, the receptive field of a first-layer 3x3 convolution is 3x3 (said to have a \"receptive field size of 3\"), and the receptive field of a second-layer 3x3 convolution based on that is 5x5.\n",
    "Activations which are based on the entire image are said to have a \"full receptive field.\" \n",
    "\n",
    "Receptive field is important because it constrains what the network could theoretically learn.\n",
    "No matter how much data you have or how powerful your model, a 1-D convolutional network on audio won't be able to transcribe (word-by-word) a full audio clip if its output units don't have receptive field big enough to encompass an entire word.\n",
    "\n",
    "Note:\n",
    " - Not every input in the receptive field contributes equally to the output. There is the concept of an [\"effective receptive field\"](http://www.cs.toronto.edu/~wenjie/papers/nips16/top.pdf) which is much smaller than the theoretical receptive field.\n",
    " - Just because a model's receptive field theoretically enables it to learn a task doesn't mean it necessarily will. Always consider whether you have enough model capacity to carry out the task and if you have enough data for the capacity.\n",
    "\n",
    "## Stride\n",
    "A common modification is **strided convolution**, which moves the kernel more than one space per step, effectively skipping steps in order to intentionally reduce the output size:\n",
    "![strided convolution](https://raw.githubusercontent.com/vdumoulin/conv_arithmetic/master/gif/no_padding_strides.gif)\n",
    "\n",
    "This is equivalent to _downsampling_ the output, performing a normal convolution and then discarding every other pixel (in the case where stride=2).\n",
    "Reducing the output size is useful for the internal \"feature extraction\" layers of a CNN, since it makes training and running the network dramatically cheaper by reducing the number of times we must slide the kernel.\n",
    "Strided convolution also increases the receptive field out the output significantly.\n",
    "\n",
    "The cost is that the features become less precisely localized, since we're discarding some of the fine-grained position.\n",
    "\n",
    "#### Aside: other kinds of convolutions\n",
    "There are a number of different varieties of convolution that have been developed recently, and are useful in certain situations.\n",
    "Transposed convolution, dilated convolution, separable convolution, and global average pooling are all important ideas in some modern convolutional networks.\n",
    "\n",
    "For more info, you might want to skim through [\"A guide to convolution arithmetic for deep learning\"](https://arxiv.org/abs/1603.07285) or play around with a [receptive field and output size calculator](https://fomoro.com/projects/project/receptive-field-calculator)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pooling\n",
    "**Pooling** is an operation very commonly used in convolutional networks.\n",
    "Pooling acts on the activation of a layer by \"grouping together\" nearby values; the most common variety is **max pooling**, which replaces every $n \\times n$ square in the activation map with the maximum activation value in that square.\n",
    "Pooling can be thought of as a sliding-window operation, much like convolution, that uses some other function instead of the linear combination function used by convolution.\n",
    "\n",
    "![maxpooling](https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png)\n",
    "(Source: [Computer Science Wiki](https://computersciencewiki.org/index.php/Max-pooling_/_Pooling))\n",
    "\n",
    "Much like striding, pooling reduces the dimensionality of the output and increases receptive field size.\n",
    "More importantly, though, it makes the output _invariant to small translations_: when you shift the input a little, the output doesn't change at all.\n",
    "This makes pooling appropriate when you care more about _whether a feature is present_ than _exactly where it is_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common architecture choices\n",
    "Deep convolutional networks follow some common design patterns:\n",
    " - First do \"feature extraction\" with stacked convolutional layers, then flatten and use 1-2 dense layers before the output layer. This allows the network to take advantage of the benefits of convolutional layers to build high-level features, then process those high-level features for a bit once locality isn't so important.\n",
    " - Downsample early in the network with strides and max pooling to make the process of feature generation cheaper and increase receptive field size. As features get higher-level, their exact spatial location matters less than whether they're present or not. At the point where locality doesn't matter at all, switch to dense layers.\n",
    " - Later layers should have more filters. This increases the channel dimensions of the activation map, allowing the network to propagate information even as the spatial dimension drops. From just a few low-level features (edges, ...) repeated many times in hierarchy, the network can learn many different high-level patterns, and needs one filter for each.\n",
    " \n",
    "A good example of a \"normal\" CNN is VGG-16:\n",
    "![vgg-16](https://alexisbcook.github.io/assets/vgg16.png)\n",
    "(Source: [\"Global Average Pooling Layers for Object Localization\"](https://alexisbcook.github.io/2017/global-average-pooling-layers-for-object-localization/))\n",
    "\n",
    "Note how after each block of convolutional layers, the network downsamples the image by a factor of 4 with max pooling and doubles the number of channels.\n",
    "It ends with two 4096-unit dense layers, then an output softmax layer for classification.\n",
    "\n",
    "An interesting fact is that despite only having three total dense layers, and most of the depth being in convolutional layers, the vast majority of the model's parameters are still in the dense layers because of how parameter-efficient convolutional layers are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution in TensorFlow\n",
    "In TensorFlow, convolution is carried out through the operations [`tf.nn.conv1d()`](https://www.tensorflow.org/api_docs/python/tf/nn/conv1d), [`tf.nn.conv2d()`](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d), and [`tf.nn.conv3d()`](https://www.tensorflow.org/api_docs/python/tf/nn/conv3d).\n",
    "These functions take an `input` tensor that represents a batch of multi-channel inputs, a `filter` tensor that has axes for both which filter (of the parallel filters) is being applied (the last axis) and for which kernel of the filter (the second-to-last axis) is being applied, and return an activation map tensor of the appropriate shape.\n",
    "\n",
    "To do max pooling, use [`tf.nn.max_pool()`](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool) regardless of the dimensions. \n",
    "\n",
    "See below for an example of how to use these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first MNIST digit. A 5.\n",
    "image = np.array([\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 18, 18, 18, 126, 136, 175, 26, 166, 255, 247, 127, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 30, 36, 94, 154, 170, 253, 253, 253, 253, 253, 225, 172, 253, 242, 195, 64, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 49, 238, 253, 253, 253, 253, 253, 253, 253, 253, 251, 93, 82, 82, 56, 39, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 18, 219, 253, 253, 253, 253, 253, 198, 182, 247, 241, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 80, 156, 107, 253, 253, 205, 11, 0, 43, 154, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 1, 154, 253, 90, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 139, 253, 190, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 190, 253, 70, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 241, 225, 160, 108, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 240, 253, 253, 119, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 186, 253, 253, 150, 27, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 93, 252, 253, 187, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 249, 253, 249, 64, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 46, 130, 183, 253, 253, 207, 2, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 148, 229, 253, 253, 253, 250, 182, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 114, 221, 253, 253, 253, 253, 201, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 23, 66, 213, 253, 253, 253, 253, 198, 81, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 18, 171, 219, 253, 253, 253, 253, 195, 80, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 55, 172, 226, 253, 253, 253, 253, 244, 133, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 136, 253, 253, 253, 212, 135, 132, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "])\n",
    "\n",
    "# Standardize\n",
    "image = (image / 128.0) - 1\n",
    "\n",
    "# The input, with dummy \"batch\" and \"channel\" dimensions\n",
    "inp = np.expand_dims(image, axis=0)\n",
    "inp = np.expand_dims(inp, axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (28, 28)\n",
      "Input shape: (1, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f93e0ad5b70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Image shape:', image.shape)\n",
    "print('Input shape:', inp.shape)\n",
    "plt.imshow(image, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f93e0a19940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUgAAAEICAYAAAA9TG1fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHiZJREFUeJzt3X20HVWd5vHvY16IrQ4EwoIASYCGHsS2F+AdXhqXMhAVsSW0ooYZNThgxIG2fcEmSI8wKN3B7tVMM6J4RTQIi5dGhYvCyoS3oV0IcqHDS0BMiDIkBGICBBgkGPKbP2qfTOVQdc65qbrnnnt4PmvVOlW1d9Xe5yT5ZVft2rsUEZiZ2Wu9YawrYGbWqxwgzcxKOECamZVwgDQzK+EAaWZWwgHSzKyEA+QYkLSnpJA0sQtl/UDS10e7nA7q8RVJl4zCeU+U9PO6z7st0p/pPmNdD6uPA2RNJP1W0u8lvZhbvjnW9RqJ9B1m13CeIyStyu+LiL+LiJOrntusm0a9BfM688GIuHmsK2EjJ2liRGwa63pYb3ELsgskTZD0j5LWSVoJfKApfS9Jd0h6QdLNki6SdHku/VBJd0p6TtL9ko5oUdaBku5L57oamNKU/heSlqZz3Snpz9L+HwIzgRtS6/dv2pUtaUdJ35f0pKRnJV0n6U3ATcBuuZb0bpLOafpOx0pals57u6S35tJ+K+l0SQ9I2iDpaklbfY8W3/8fJP1c0vZp+79IeiTVb7GkWbm8IelUScuB5bl9p0hanup2kSTljik9n/WhiPBSwwL8FphdknYK8CtgBrAjcBsQwMSU/gvgH4HJwDuB54HLU9ruwHrgGLL/0N6TtncuKGcy8DjwBWAScDzwB+DrKf1AYC1wCDABmJfqvV3Rd2hXNvAz4Gpgairv3Wn/EcCqprqdk/tOfwL833S+ScDfACuAybl6/BLYLf1ejwCnlPy2JwI/T/X7LrAY+KOUNied961kV0t/C9yZOzaAJamMN+b2/RTYgew/jN8BR4/gfPuM9d9FL/UtY16BflnSP+oXgedyy6dT2q35f+DAexsBMv0j3NT4R53SL88FkzOAHzaVtRiYV1CHdwFPAsrtuzMXIL8NfK3pmEdzga05QJaWDUwHNgNTC+rRLkD+N+CaXNobgNXAEbl6fDyX/g3g4pLf/UTgbrJA/aNGkE1pNwEnNZXzEjArbQdwZNP5AnhnbvsaYMEIzucA2UeLL7HrdVxE7JBbvpv27wY8kcv3eG59N+CZiHgpty+fdxbwkXS595yk58hamdMLyt8NWB3pX2tBWbOALzWda0Y6rkirsmekej9bcmwru+XrFRGbyb7z7rk8T+XWXwLe3OJ8+5C17v57RLzSVP9/ztX9GUBN5eR/63Zld3I+6yPupOmONWQBpWFmU9qOkv4oFyTzeZ8ga8V9usNydpekXJCcCTyWO9d5EXFeyfHNUzuVli1peqr3DhHxXJvzNHsSeHvuXCL7zqvbHFfmEeAi4CZJR0bEo7n6nxcRV7Q4diTTWXVyPusjbkF2xzXA5yTtIWkqsKCREBGPA8PAOZImSzoM+GDu2MuBD0p6X+rsmZIeo9mjoJxfkF2uf07SJEkfAg7OpX8XOEXSIcq8SdIHJL0lpT8N7N1J2RGxhuyS81uSpqby3pU7z06NjpKS3+MDko6SNAn4ErCR7HbANomIK4GvADdL+uO0+2LgTElvA5C0vaSPbGsZo3A+63EOkPVq9AA3lp+k/Y3Og/uB+4AfNx33n4HDyDpAvk52P20jQEQ8QXb5+BWyDoMngC9T8GeXLi8/RHZf7hngY/myImIY+DTwTeBZsg6HE3On+Hvgb9Ml5OkdlP0Jsk6gX5F1/nw+lfMr4EpgZTrXVpfwqYX3ceB/AuvI/kP4YNPl8YhFxCLgXOBWSXtGxE+A84GrJD0PPAS8v8L5az2f9T5tfbvKekF6POdXEXH2WNfF7PXMLcgeIOk/SPpjSW+QdDRZq+26sa6X2etdpQCZHhRekh6qXZLurxXle1XZw8lLJQ1VKbNP7QrcTvaY0IXAZyPi38a0RmZjQNKlktZKeqgkXZIulLQiDSQ4KJc2L8Wi5ZLm1VKfKpfYkr5B9qjHQkkLyJ6JO6Mg34sR0eoxDTMzUkffi8BlEfGnBenHAH9FNnjhEOCfI+IQSTuSdXYOkD2ZcC/wjm18DG2LqpfYc4BFaX0RcFzF85nZ61hE3EHWwVhmDlnwjIi4C9ghPXL2PmBJRDSezV0CHF21PlWfg9wlPe4B2cO1u5TkmyJpmOwRlIURUXh/TdJ8YD7Am970pnfst99+FatnZq3ce++96yJi5yrn2EfaapRDK2tgGfBybtdgRAyOoLjd2frh/lVpX9n+StoGSEk3k90ja3ZWfiMiQlLZ9fqsiFgtaW+yRzAejIjHmjOlH2oQYGBgIIZ/+cu2X8DMtp0mTHi8fa7WXgI+02Hec+DliBioWma3tA2QEVE6P6CkpyVNj4g1qZm7tuQcq9PnSkm3k02a8JoAaWbjj+jq4zCr2Xqk2R5p32qyOQDy+2+vWljV7zVENnEB6fP65gxplMV2aX0acDjwcMVyzaxHiKyl1clSgyHgk6k3+1BgQ7rNtxh4b4o3U8kmhFlctbCqdV4IXCPpJLLJBz4KIGmAbPaak8mmhvqOpM1kAXlhRDhAmvWRulqQkq4kawlOUzYr/dlkU+IRERcDN5L1YK8gu7r/VEp7RtLXgHvSqc6NiFadPR2pFCAjYj1wVMH+YeDktH4nuYkJzKz/1BUgI+KENukBnFqSdilwaU1VATybj5lV1OV7kF3lAGlmlTlAmpkVcAvSzKyFCWNdgVHiAGlmlQgHSDOzUr7ENjMr4HuQZmYtOECamRVoDDXsR/36vcysi9yCNDMroLT0IwdIM6vMj/mYmRVwL7aZWQsOkGZmBdyLbWbWgluQZmYFfA/SzKyFfn3Mp18Dv5l10YQOl3YkHS3pUUkrJC0oSL9A0tK0/FrSc7m0V3NpQ3V8L7cgzaySujppJE0ALgLeA6wC7pE0lH/JX0R8IZf/r8heId3w+4g4oIaqbOEWpJlV0rgH2cnSxsHAiohYGRGvAFcBc1rkPwG4skLV23KANLPKagqQuwNP5LZXpX2vIWkWsBdwa273FEnDku6SdNyIv0QBX2KbWWUjaGlNkzSc2x6MiMFtKHIucG1EvJrbNysiVkvaG7hV0oMR8dg2nHsLB0gzq2SEj/msi4iBkrTVwIzc9h5pX5G5NL0fOyJWp8+Vkm4nuz9ZKUD6EtvMKlOHSxv3APtK2kvSZLIg+JreaEn7AVOBX+T2TZW0XVqfBhwOPNx87Ei5BWlmlQiYVMN5ImKTpNOAxWRPBV0aEcsknQsMR0QjWM4FroqIyB3+VuA7kjaTNfwW5nu/t5UDpJlVVtelaETcCNzYtO+rTdvnFBx3J/D2mqqxRS3fq4OHO7eTdHVKv1vSnnWUa2Zjr8bHfHpO5TrnHu58P7A/cIKk/ZuynQQ8GxH7ABcA51ct18x6hwNkuU4e7pwDLErr1wJHSerX4ZtmrytuQbbWycOdW/JExCZgA7BTDWWbWQ/o1wDZU500kuYD8wFmzpw5xrUxs07084S5dQT1Th7u3JJH0kRge2B984kiYjAiBiJiYOedd66hambWDf3agqyjzp083DkEzEvrxwO3Nj3DZGbjVD/fg6zcMu7w4c7vAT+UtAJ4hiyImlmfGI/BrxO13Dpo93BnRLwMfKSOssys9zhAmpkV6OdOmn79XmbWRf36ULMDpJlVIjp738x45ABpZpX5HqSZWQG/F9vMrAUHSDOzAu7FNjMr4UtsM7MWHCDNzEr0a4Ds1+9lZl1S52QVHby+5URJv5O0NC0n59LmSVqelnnNx24LtyDNrLI6Wlq517e8h2zi7XskDRW8nfDqiDit6dgdgbOBASCAe9Oxz1apk1uQZlZJoxe7k6WNTl7fUuZ9wJKIeCYFxSXA0SP6IgUcIM2sMkkdLcA0ScO5ZX7uNJ28vgXgw5IekHStpMZk3Z0eOyK+xDazaiSY2GEo+cMf1kXEQIXSbgCujIiNkj5D9jLAIyucryW3IM2suokTO1taa/v6lohYHxEb0+YlwDs6PXZbOECaWTWNFmT1ANn29S2Spuc2jwUeSeuLgfdKmippKvDetK8SX2KbWTVveANMmdJZ3hdeKE3q8PUtn5N0LLCJ7PUtJ6Zjn5H0NbIgC3BuRDyzbV/o/3OANLNqRnIPso0OXt9yJnBmybGXApfWUpHEAdLMqqspQPaa/vxWZtY9NbYge01/fisz6x4HSDOzEg6QZmYlpM57sccZB0gzq8YtSDOzEg6QZmYlHCDNzEr0cYCsZSx2lVmAzawP1DMWu+dUrnGVWYDNrA+MZCz2OFNHSN8yCzCApMYswM0B0sz6UR9fYtfxrYpm8j2kIN+HJb0L+DXwhYh4ojlDml04zTD8RjSh09nWX3/O5qdjXYWed86rr451FV4f+jhAdms+yBuAPSPiz8jeFbGoKFNEDEbEQDbj8OQuVc3MKqlvPsieU0eNO5oFOLd5CfCNGso1s14xDoNfJ+r4VltmASYLjHOB/5TPIGl6RKxJm/lZgM1svHMnTbkqswCbWR/o43uQtXyrKrMAm9k418cB0i/tMrPqauqk6WDQyRclPZzei32LpFm5tFdzg1GGmo/dpq9Vx0nM7HWsphZkh4NO/g0YiIiXJH2WrMP3Yynt9xFxQOWK5LgFaWbV1PeYz5ZBJxHxCtAYdLJFRNwWES+lzbvInpoZNW5Bmlk1I+vFniZpOLc9GBGDab3TQScNJwE35banpHNvAhZGxHWdVqqMA6SZVdf5Jfa6bCBINZI+DgwA787tnhURqyXtDdwq6cGIeKxKOQ6QZlZNfb3YbQedZMVpNnAW8O6I2NjYHxGr0+dKSbcDBwKVAqTvQZpZNfXdg9wy6ETSZLJBJ1v1Rks6EPgOcGxErM3tnyppu7Q+DTicGibMcQvSzKqpqQXZ4aCTfwDeDPyLJID/ExHHAm8FviNpM1nDb2HBlIsj5gBpZtXU+FbDDgadzC457k7g7bVUIscB0syq6eORNP35rcysexwgzcxKOECamZVwgDQzK+EAaWZWosZe7F7jAGlm1bgFaWZWwgHSzKyEA6SZWQsOkGZmBdyCNDMr4de+mpmVcAvSzKwFB0gzswJuQZqZlXCANDMr4U4aM7MW+rQFWctLuyRdKmmtpIdK0iXpQkkrJD0g6aA6yjWzHlDfS7uQdLSkR1OsWFCQvp2kq1P63ZL2zKWdmfY/Kul9dXy1ut5q+APg6Bbp7wf2Tct84Ns1lWtmY62mAClpAnARWbzYHzhB0v5N2U4Cno2IfYALgPPTsfuTvQXxbWSx6FvpfJXUEiAj4g7gmRZZ5gCXReYuYAdJ0+so28zGWH0tyIOBFRGxMiJeAa4iix15c4BFaf1a4ChlrzecA1wVERsj4jfAinS+Srp142B34Inc9qq0b00+k6T5ZC1M4I1dqpqZVTKyXuxpkoZz24MRMZjWi+LEIU3Hb8mTXhO7Adgp7b+r6djdO61UmZ66s5p+qEEAaYcY4+qYWQci4JVNHV+MrouIgdGsT526FSBXAzNy23ukfWY2zkXApk21nKqTONHIs0rSRGB7YH2Hx45YXZ007QwBn0y92YcCGyJiTbuDzKz3NQJkJ0sb9wD7StpL0mSyTpehpjxDwLy0fjxwa0RE2j839XLvRdYh/Muq362WFqSkK4EjyO4vrALOBiYBRMTFwI3AMWQ3Tl8CPlVHuWY29upqQaZ7iqcBi4EJwKURsUzSucBwRAwB3wN+KGkFWcfw3HTsMknXAA8Dm4BTI+LVqnWqJUBGxAlt0gM4tY6yzKz31HSJTUTcSNagyu/7am79ZeAjJceeB5xXT00yPdVJY2bjT433IHuOA6SZVbJ5M7z88ljXYnQ4QJpZJW5Bmpm14ABpZlbALUgzsxIOkGZmJdxJY2bWgluQZmYFfIltZlbCAdLMrIQDpJlZCQdIM7MSEe7FNjMr5BakmVkJB0gzsxIOkGZmJRwgzcxa6NcA2a2XdplZn2qMxe5kqULSjpKWSFqePqcW5DlA0i8kLZP0gKSP5dJ+IOk3kpam5YB2ZTpAmlklNb7VsJ0FwC0RsS9wS9pu9hLwyYh4G3A08D8k7ZBL/3JEHJCWpe0K9CW2mVXSxXuQc8jengqwCLgdOGPrusSvc+tPSloL7Aw8ty0FugVpZpWNoAU5TdJwbpk/gmJ2iYg1af0pYJdWmSUdDEwGHsvtPi9del8gabt2BboFaWaVjLAFuS4iBsoSJd0M7FqQdNbWZUZIihbnmQ78EJgXEZvT7jPJAutkYJCs9Xluq8o6QJpZJXVOmBsRs8vSJD0taXpErEkBcG1Jvn8H/Aw4KyLuyp270frcKOn7wOnt6uNLbDOrpIudNEPAvLQ+D7i+OYOkycBPgMsi4tqmtOnpU8BxwEPtCnQL0swq61InzULgGkknAY8DHwWQNACcEhEnp33vAnaSdGI67sTUY32FpJ0BAUuBU9oV6ABpZpV0qxc7ItYDRxXsHwZOTuuXA5eXHH/kSMus5RJb0qWS1koqbLJKOkLShtwDml+to1wzG3tdvMTuurpakD8Avglc1iLPv0bEX9RUnpn1CI/FbiMi7pC0Zx3nMrPxxRPm1uMwSfcDTwKnR8Sy5gzpodH5ADNnzuTx37ymk8rMeoxbkNXdB8yKiBclHQNcB+zbnCkiBske4GRgYKD0IVAz6x39HCC78hxkRDwfES+m9RuBSZKmdaNsMxtd7qSpSNKuwNNpeNDBZIF5fTfKNrPR1c8tyFoCpKQryWbZmCZpFXA2MAkgIi4Gjgc+K2kT8HtgbkT4EtqsD7iTpo2IOKFN+jfJHgMysz7jFqSZWQkHSDOzEg6QZmYlHCDNzFpwgDQzK1DnhLm9xgHSzCrxJbaZWQkHSDOzFhwgzcwK9HML0i/tMrNKujVZhaQdJS2RtDx9Ti3J92ru7QVDuf17Sbpb0gpJV6cXfLXkAGlmlTR6sTtZKloA3BIR+wK3pO0iv4+IA9JybG7/+cAFEbEP8CxwUrsCHSDNrLIuTXc2B1iU1heRvbq1I+lVr0cCjVfBdnS870GaWSUjvAc5TdJwbnswTZTdiV0iYk1afwrYpSTflFTGJmBhRFwH7AQ8FxGNmq4Cdm9XoAOkmVUWsbnTrOsiYqAsUdLNwK4FSWdtXV6EpLIpE2dFxGpJewO3SnoQ2NBpBfMcIM2sogBeredMEbPL0iQ9LWl6RKyRNB1YW3KO1elzpaTbgQOBHwE7SJqYWpF7AKvb1cf3IM2sogBe6XCpZAiYl9bnAa95q5+kqZK2S+vTgMOBh9ME3beRTd5denwzB0gzq8HmDpdKFgLvkbQcmJ22kTQg6ZKU563AcHqD6m1k9yAfTmlnAF+UtILsnuT32hXoS2wzq6i+S+yWpUSsB44q2D8MnJzW7wTeXnL8SuDgkZTpAGlmFXUnQI4FB0gzq4EDpJlZAbcgzcxKBPCHsa7EqHCANLOK3II0M2vBAdLMrIBbkGZmLVR+CLwnOUCaWUX924KsPNRQ0gxJt0l6WNIySX9dkEeSLkwz+T4g6aCq5ZpZr+jaWOyuq6MFuQn4UkTcJ+ktwL2SluTGPwK8H9g3LYcA306fZjbuuQVZKiLWRMR9af0F4BFeOxHlHOCyyNxFNu3Q9Kplm1mv6MpkFV1X6z1ISXuSzb12d1PS7sATue3GbL5rMLNxrn9bkLUFSElvJpuU8vMR8fw2nmM+MB9g5syZdVXNzEZdfwbIWuaDlDSJLDheERE/LsiyGpiR2y6czTciBiNiICIGdt555zqqZmajrn87aeroxRbZxJOPRMQ/lWQbAj6ZerMPBTbkXr5jZuNa4HuQ5Q4HPgE8KGlp2vcVYCZARFwM3AgcA6wAXgI+VUO5ZtYz+vMSu3KAjIifA2qTJ4BTq5ZlZr2ofztp/E4aM6uoESA7WbadpB0lLZG0PH1OLcjzHyUtzS0vSzoupf1A0m9yaQe0K9MB0sxq0JV7kAuAWyJiX+CWtL2ViLgtIg6IiAOAI8lu6f2vXJYvN9IjYmnz8c0cIM2soq71Ys8BFqX1RcBxbfIfD9wUES9ta4EOkGZWUXcusYFdck+/PAXs0ib/XODKpn3npfkgLmi8P7sVz+ZjZjXoOPhNkzSc2x6MiMHGhqSbgV0LjjsrvxERISnKCklDmd8OLM7tPpMssE4GBsnek31uq8o6QJpZRY3nIDuyLiIGSs8UMbssTdLTkqZHxJoUANe2KOejwE8iYsvLcnKtz42Svg+c3q6yvsQ2s4q6dok9BMxL6/OA61vkPYGmy+vGBDlpcMtxwEPtCnSANLMadCVALgTeI2k5MDttI2lA0iWNTGnSnBnA/246/gpJDwIPAtOAr7cr0JfYZlZRoxd7lEuJWA8cVbB/GDg5t/1bXjvlIhFx5EjLdIA0s4pGdA9yXHGANLMa9OdQQwdIM6uof8diO0CaWUUOkGZmJbrTSTMWHCDNrAbupDEzK+BLbDOzFhwgzcwKuAVpZtaC70GamRXYjHuxzcxK+RLbzKyA70GambXge5BmZgXcgjQza8EB0sysgHuxzcxacAvSzKxA/84oXvmlXZJmSLpN0sOSlkn664I8R0jaIGlpWr5atVwz6yWj/9IuSR9JMWazpNJXx0o6WtKjklZIWpDbv5eku9P+qyVNbldmHW813AR8KSL2Bw4FTpW0f0G+f42IA9LS8mXdZjaedO21rw8BHwLuKMsgaQJwEfB+YH/ghFw8Oh+4ICL2AZ4FTmpXYOUAGRFrIuK+tP4C8AgFbxQzs34VwB86XCqUEvFIRDzaJtvBwIqIWBkRrwBXAXPSu7CPBK5N+RaRvRu7pVrvQab30R4I3F2QfJik+4EngdMjYlnB8fOB+WlzoyZMaPti7y6bBqwb60rkuD6t9Vp9oPfq9O+rn2LDYrhhWoeZp0gazm0PRsRg9TpssTvwRG57FXAIsBPwXERsyu1v25CrLUBKejPwI+DzEfF8U/J9wKyIeFHSMcB1wL7N50g/1GA633BElN5nGAu9VifXp7Veqw/0Xp2agtU2iYij66gLgKSbgV0Lks6KiOvrKqdTtQRISZPIguMVEfHj5vR8wIyIGyV9S9K0iOil/0nNbIxFxOyKp1gNzMht75H2rQd2kDQxtSIb+1uqoxdbwPeARyLin0ry7JryIengVO76qmWbmTW5B9g39VhPBuYCQxERwG3A8SnfPKBti7SOXuzDgU8AR+Ye4zlG0imSTkl5jgceSvcgLwTmpgq3Uud9ibr0Wp1cn9Z6rT7Qe3XqtfqUkvSXklYBhwE/k7Q47d9N0o0AqXV4GrCYrMP4mlx/xxnAFyWtILsn+b22ZbaPU2Zmr091tCDNzPqSA6SZWYmeCZCSdpS0RNLy9Dm1JN+ruXudQ6NQj8JhSrn07dIwpRVp2NKedddhG+p0oqTf5X6Xk0exLpdKWiup8BlVZS5MdX1A0kGjVZcR1KlrQ107HHrb1d/Iw4EriIieWIBvAAvS+gLg/JJ8L45iHSYAjwF7A5OB+4H9m/L8V+DitD4XuHqUf5dO6nQi8M0u/Tm9CzgIeKgk/RjgJkBkQ0/v7oE6HQH8tEu/z3TgoLT+FuDXBX9eXf2NOqxT136j8bT0TAsSmEM2/Ac6HAY0CgqHKTXlydfzWuCoxiNMY1inromIO4BnWmSZA1wWmbvInj2bPsZ16probOhtV3+jDutkBXopQO4SEWvS+lPALiX5pkgalnSXpLqDaNEwpea/SFvyRPZIwQayRwZGSyd1Avhwuly7VtKMgvRu6bS+3XaYpPsl3STpbd0osMXQ2zH7jToZDtzN36jXdXU+yFbDiPIbERGSyp4/mhURqyXtDdwq6cGIeKzuuo4zNwBXRsRGSZ8ha+EeOcZ16iUdDXWtU5uht2OiTZ26/huNB11tQUbE7Ij404LleuDpxmVG+lxbco7V6XMlcDvZ/4Z1KRumVJhH0kRge0Z3VFDbOkXE+ojYmDYvAd4xivVpp5PfsKsi4vmIeDGt3whMktTp5Aoj1m7oLWPwG3UyHLibv9F40UuX2ENkw3+gZBiQpKmStkvr08hG8TxcYx0Khym1qOfxwK2R7nKPkrZ1arp/dSzZPaaxMgR8MvXUHgpsyN06GRPq4lDXVE7Lobd0+TfqpE7d/I3GlbHuJWosZPfxbgGWAzcDO6b9A8Alaf3PgQfJenIfBE4ahXocQ9bL9xjZDCIA5wLHpvUpwL8AK4BfAnt34bdpV6e/B5al3+U2YL9RrMuVwBqyyf1WkU06egpwSkoX2YSlj6U/o4Eu/D7t6nRa7ve5C/jzUazLO8kmSHwAWJqWY8byN+qwTl37jcbT4qGGZmYleukS28yspzhAmpmVcIA0MyvhAGlmVsIB0syshAOkmVkJB0gzsxL/D4b7FaQKDAYqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define an edge detection kernel\n",
    "kernel_edge = np.array([[ 0, 0, 0],\n",
    "                        [-1, 1, 0],\n",
    "                        [ 0, 0, 0]])\n",
    "\n",
    "plt.imshow(kernel_edge, cmap='seismic')\n",
    "plt.title('Edge detection kernel')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f93e09549b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a Gaussian blur kernel\n",
    "kernel_blur = np.array([[1, 2, 1],\n",
    "                        [2, 4, 2],\n",
    "                        [1, 2, 1]])\n",
    "\n",
    "plt.imshow(kernel_blur, cmap='seismic', vmin=0, vmax=5)\n",
    "plt.title('Gaussian blur kernel')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filters tensor shape: (3, 3, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Combine the kernels into two filters, each of shape [3, 3, 1]\n",
    "filters = np.stack((kernel_edge, kernel_blur), axis=-1)\n",
    "filters = np.expand_dims(filters, axis=2)\n",
    "print('Filters tensor shape:', filters.shape) # [3, 3, 1, 2]\n",
    "# Corresponds to two 3x3 filters, each with 1 kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tiny graph for applying both kernels to the image\n",
    "inp_tensor = tf.constant(inp, dtype=tf.float64)\n",
    "filter_tensor = tf.constant(filters, dtype=tf.float64)\n",
    "\n",
    "activation_tensor = tf.nn.conv2d(\n",
    "    input=inp_tensor,\n",
    "    filter=filter_tensor,\n",
    "    strides=(1, 1, 1, 1), # Stride 1 in each dimension\n",
    "    padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolve both filters over the input\n",
    "with tf.Session() as sess:\n",
    "    activation = sess.run(activation_tensor)\n",
    "    \n",
    "# Extract individual activation maps\n",
    "activation_edge = activation[0, :, :, 0]\n",
    "activation_blur = activation[0, :, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f93f226f240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATYAAAEICAYAAADVzNh0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHjVJREFUeJzt3X+UXGWd5/H3hyTABJAAjSHkB0FhjqKO6GYxjBmNE3QQQRABYRY2uGrAA0dlxTEjClkHZ7MeFVhwxIAICBJYRjBKFBXkIKsogYlC+KExm5AOIaH5ZUijEPLdP+5tuF1ddW91V1VX1e3P65w6Xfc+Tz3Pt359+7k/6rmKCMzMymSHdgdgZtZsTmxmVjpObGZWOk5sZlY6TmxmVjpObGZWOqVObJJmSgpJ40ehryslnd/qfuqI43OSLm93HHkkXSrpCy1qe5Wkua1o27pH1yU2SWslPS/pucztknbHNRzpczisCe3MldSbXRcR/xoRH2207WaRdKqku7LrIuL0iPiXJrQ95J9JRLwhIu5otG3rbi0fybTIURHxs3YHYWYdKiK66gasBQ6rUTYO+ArQB6wBzgACGJ+W7w/cCWwBfgZ8Hbgm8/jZwC+BZ4DfAnNz4ngLcF/a1vXAUuD8TPmRwMq0rV8Cf5Ou/w6wHXgeeA74p6K+gT2BbwOPAU8DNwO7pG1sT9t5DtgXWFTxnN4PrErbvQN4fcVreTbwO+DZ9HnsXOP5vha4HXgyfX2vBSZlyqcD3wOeSOtcArwe+DPwUhrfM2ndKwdeK+Ah4MhMO+PTNt6aLv8f4PE0vjuBN6TrFwAvAi+kbf+g8vMB7ARcmL5uj6X3d0rL5gK9wKeBzcBG4MM57/cdwPnpe/Qc8ANgr/R1+BNwDzAzU/8iYH1adi/wd5myRcCN6eu9heRz9OZ2f7fKdGt7AMMOOD+xnQ48nH7J9gR+zuDE9iuSxLcjMCf90F2Tlk1Nv5BHkGyivztd3rtKPzsC64CzgAnAcemXbODL+pb0y/I2kmQ7P417p2rPoahv4Jb0S7BH2t870/Vzgd6K2BZlntNfA1vT9iYA/wSsBnbMxPEbkoS4J0mSOb3Ga3tA2s5OwN4kSebCtGwcSTK+gCTh7gzMSctOBe6qaOvKzGt1LnBtpux9wEOZ5f8G7MYrSWpltXaqfT6ALwJ3A69OY/4l8C+Z125bWmdC+tr3A3vUeP53pK/da4HdgQeB3wOHkSTjq4FvZ+qfTJL4xpMkz8dJ/2mk79GLJJ+bCST/XP4fMKHd36+y3NoewLADTj64z5GMQAZuH0vLbs9+MYH3kCY2YEb6QZ6YKb8mkwQ+C3ynoq9bgflVYngHyQhAmXW/zHxZvzHwBcqUP8IrCenlL19R38AUklHZkC8cxYntC8ANmbIdgA2ko8E0jpMz5V8GLq3zfTgG+I/0/qEko6zxVeqdSn5iO4Bk1DIxXb4WOLdGn5PS93P3ynYqPh8Die2PwBGZsn8A1mZeu+ezMZP8M5pdo+87gHMyy18FfpRZPopM0q3y+KdJR2Xpe3R3xfuykcyozrfGbl138CB1TERMytwuS9fvSzL8H7Auc39f4KmI6M+sy9bdDzhe0jMDN5JR3ZQq/e8LbIj0U1mlr/2AT1e0NT19XDV5fU9P4366xmPz7JuNKyK2kzznqZk6j2fu9wO7VmtI0mRJSyVtkPQnkn8KPWnxdGBdRGwbboARsZpkpHiUpIkkm87fTfscJ2mxpD+mfa5NH9ZTtbGhBj3/9H72PXiyIuaazz+1KXP/+SrLLz9W0tmSHpL0bPp+7l4R98ufvfR96aX258OGqVsPHtSykeRLNmBGRdmekiZmklu27nqSUdPH6uxnqiRlktsMkhHCQFtfiogv1Xh85ZQqNfuWNCWNe1JEPFPQTqXHgDdl2hLJc95Q8Lhq/jXt700R8ZSkY0j2ow3EP0PS+CrJrZ7pY64DTiIZuTyYJjuAfwSOJtncW0uSHJ4GVGfbj5H801iVLs9I17WUpL8j2eyfB6yKiO2SsnFD5rMnaQdg2mjENlZ064itlhuAT0iaJmkPYOFAQUSsA1YAiyTtKOlQks2HAdeQjBr+IR0p7JyeTjGtSj+/Itms/YSkCZKOBQ7JlF8GnC7pbUrsIul9knZLyzcBr6mn74jYCPwI+DdJe6T9vSPTzl6Sds95Pd4naZ6kCST7ev5Cstk8XLuR7AJ4VtJU4DOZst+QJPvF6XPdWdLbMzFOk7RjTttLSXYbfJx0tJbp8y8k+xsnkiTXrMrXsdJ1wOcl7S2ph2R/3jU59ZtlN5LPxxPAeEnnAq+qqPOfJB2bnmP5KZLnefcoxDYmdGti+0HFeWw3pesvI9k39VuSI03fq3jcfyHZH/QkyRGu60k+UETEepLRwedIPpDrSb68Q16jiHgBOJZk/9FTwIeyfUXECuBjJCOap0l2Op+aaeJ/knzhnpF0dh19n0Kys/lhkv1An0r7eZjky7smbWvQpkxEPEKyE/tikiOZR5GcKvNClde0yP8A3kpydPKWiuf7Utr2AcCjJJtVH0qLbycZMT0uqa9aw2ny/hXwtyTvyYCrSTYfN5DsrK/84n8LOCh97jdXafp8kn9mvwPuJ/lMjMZJ1LcCPyY5uLCO5Mjw+oo63yd5jZ4meX+PjYgXRyG2MUGDdxONLZKuBx6OiPPaHYuNHZIWAQdExMntjqWsunXENiKS/rOk10raQdLhJKOkav/pzayLle3gQZF9SDah9iLZXPp4RPxHe0Mys2Yb05uiZlZOY2pT1MzGhlHdFO3p6YkZM2aOZpdmY8qjj66lr69PxTVrO0AadBZ7no1wa0Qc3kh/rdBQYkt3wF9E8lvByyNicV79GTNmctddKxrp0sxyzJkzq+E2+oHT6qy7qP5fgYyqEW+KShpHMjvGe4GDgJMkHdSswMysPUSSGOq5dapGYjsEWB0Ra9ITPpeSnD5hZl1MJJty9dw6VSOJbSqDz6buZfCPq82sS43lEVtdJC2QtELSir6+J1rdnZk1wVhObBsYPDvGNKrMGhERSyJiVkTM6unZu4HuzGw0jPV9bPcAB0raP5254URgWXPCMrN26vbENuL9fxGxTdKZJDMZjAOuiIhVBQ8zsw43MGLrZg0d2IiI5cDyJsViZh1iXLsDaFAnH7E1szYQTmxmVkJjelPUzMpnzO9jM7NycmIzs1IZ+ElVN+v2+M2sBTxiM7NSEYMvgNqNnNjMbAif7mFmpeKjomZWSk5sZlYqPipqZqXU7SO2bo/fzJqsmfOxSbpC0mZJD9QonyvpWUkr09u5zXgOHrGZ2RBNPN3jSuAS4OqcOr+IiCOb16UTm5lV0azTPSLiTkkzm9Rc3bwpamaDtOEqVYdK+q2kH0l6QzMa9IjNzAYZ5nlsPZKyV0FfEhFLhtHdfcB+EfGcpCOAm4EDh/H4qpzYzGyIYSS2vogY8eXnI+JPmfvLJf2bpJ6I6Btpm+BNUTOrYrQu5iJpH0lK7x+SNvtko+16xGZmgzTzJ1WSrgPmkmyy9gLnARMAIuJS4Djg45K2Ac8DJ0ZENNqvE5uZDdGs0z0i4qSC8ktITgdpKic2MxtEpEOqLubEZmZDdPvOdyc2MxvE0xZZR9t55+I6O/Rtzi3v3/XVDccx8eC/zq+wYkV+OcAvfpFbrCNn5JY/zd8UdjHpqKNyyx+7dFlu+dSpLxX2AVvzS7e+qo42Ws+JzcxKxSM2MyslJzYzKxVPNGlmpeQRm5mVivexmVkpObGZWek4sVlVEx/4TX6Fgw/OL7+kjp/PbduWX37yycVtnH12fvnl3y1uo0D/yt833Mbdf/W+3PLFi/MfP2nVKYV9PHp+3uzV8MObi1p4prCPs87aq7BOu435gweS1gJbgJeAbY3My2RmnaOJ1zxoi2Yk5nc1OimcmXUO0bxrHrRLt484zawFun0fW6PxB/ATSfdKWlCtgqQFklZIWtHX90SD3ZlZqzXzuqLt0mhscyLircB7gTMkvaOyQkQsiYhZETGrp2fvBrszs9EwphNbRGxI/24GbgIOaUZQZtY+bbj8XtONOLFJ2kXSbgP3gfcAVS9jb2bdowyboo0k3cnATekFZsYD342IHzclqg438cb8850Abp8/P7f87zdtyi3vP/2/DyumEWvCeWqNKjodD2DevP+bW75u3dtzy/t7it+ztQXTws2dm19+7bXF56gdc0xhlY7QyUmrHiNObBGxBnhzE2Mxsw7RxKtUXQEcCWyOiDdWKRdwEXAE0A+cGhH3NdpvtydmM2uyJm+KXgkcnlP+XpIrvx8ILAC+MaKgKzixmdkQzUpsEXEn8FROlaOBqyNxNzBJ0pRGYofOPrBhZm0wzN+K9kjK7p1cEhFLhtHdVGB9Zrk3XbdxGG0M4cRmZkOkBwWLRfR14m/EndjMbDAJxteZGl58sdHeNgDTM8vT0nUN8T42Mxtq/Pj6bo1bBvxXJWYDz0ZEQ5uh4BGbmVUazoitsCldB8wl2RfXC5wHTACIiEuB5SSneqwmOd3jw83o14ltJIrO1ASeK6rw8MP55bMav1BxM1x4YX55PSecHnTjF3PLN512bh2R5M8k2dPzgzrayDerwT1FM2c2HEJn2GGH+q62DbBlS25xRJxUUB7AGfWGVi8nNjMbrIkjtnbp7ujNrDWc2MysVDxiM7PScWIzs9JxYjOz0pHqPyraoZzYzGwwj9jGpv6eGYV13v/hgvMMly7NLb585ZDLRwxx4ifzf8+369YobOPyy/PLzzkn/0S2k0/+VGEfvHHINFyDTJ69f3Eb3FBHHWsKJzYzKx0nNjMrHSc2MyslJzYzK5Xh/Fa0Qzmxmdlg3hQ1s9JxYjOz0nFis1r6L7kit3zic5tzy48snNANXvhkfvnEeYcWtvHJu8/PLT/00Pzz1Hp6Crug//Bj8ysUlQNbi7uxZnJiM7NS8cEDMysdb4qaWemUILH5KlVmNlQTr1Il6XBJj0haLWlhlfJTJT0haWV6+2jD4TfagJmVTHOvUjUO+DrwbpKrvN8jaVlEPFhR9fqIOLMpneLEZmaVmrspegiwOiLWJE1rKXA0UJnYmsqJzcwGG95R0R5JKzLLSyJiSWZ5KrA+s9wLvK1KOx+U9A7g98BZEbG+Sp26ObGZ2VD1j9j6IqLBK7LyA+C6iPiLpNOAq4C/b6RBJ7Y26d81/4LI++xa3Ma2ogpr1xa2cdZZ83LLL7jgm/kxbDutsI8uP8A29jR3U3QDMD2zPC1d97KIeDKzeDnw5UY7LTwqKukKSZslPZBZt6ekn0r6Q/p3j0YDMbMOMZDYmnNU9B7gQEn7S9oROBFYNrg7Tcksvh94qNGnUM/pHlcCh1esWwjcFhEHArely2ZWBk1MbBGxDTgTuJUkYd0QEaskfVHS+9Nqn5C0StJvgU8Apzb6FAoji4g7Jc2sWH00MDe9fxVwB/DZRoMxsw7Q5KtURcRyYHnFunMz9/8Z+OemdcjI97FNjoiN6f3Hgcm1KkpaACwAmD69+CIoZtZm/uUBREQANS+HFBFLImJWRMzq6dm70e7MrNWau4+tLUYa2SZJUyJiY7rjL38OHjPrHmN4xLYMmJ/enw98vznhmFnbjYURm6TrSA4U9EjqBc4DFgM3SPoIsA44oZVBWnWvevbZ3PK7d9+9sI2v7fWl3PILmJZbfvbZhV1wYf41l63TlGDEVs9R0ZNqFOWf2Wlm3anJR0XbobvTspk131gYsZnZGOPEZmal48RmZqXkxGZmpeIRm5mVji+/Z2al4xGbtVP/+Fflls++7bbCNm6cl3864qpVNX8GDMCllxZ2wcUX55dfdFFxG6tXF9exJnJiM7NS8YjNzErHic3MSscHD8yslDxiM7NS8aaomZVOCRJbw1ODm1nJNHmiSUmHS3pE0mpJQ65oJ2knSden5b+ucvGoYevutGy5+mcXX0z7uFNOyS1f8wbllv/vJ5/MLQfo33nP3PKFCzfmlgPMmTMlt7xoMstZjV6rfCxp4ohN0jjg68C7gV7gHknLIuLBTLWPAE9HxAGSTgT+F/ChRvr1iM3MBomAF7btUNetDocAqyNiTUS8ACwluXxn1tEkl/EEuBGYJyn/P2oBj9jMbJAI2Lat7uo9klZklpdExJLM8lRgfWa5F3hbRRsv14mIbZKeBfYC+oYTd5YTm5kNMszE1hcRHbeh78RmZoMMM7EV2QBMzyxPS9dVq9MraTywO1C88zaH97GZ2RDbttV3q8M9wIGS9pe0I3AiyeU7s7KX8zwOuD29EPuIecRmZoM0c8SW7jM7E7gVGAdcERGrJH0RWBERy4BvAd+RtBp4iiT5NcSJzcwG2b4d/vzn5rUXEcuB5RXrzs3c/zNwfPN6dGIb8/ovvTq3/DVHHplb/sxeexX2MekLX8gt37r1i4VtvPGN+eXvfGf+N/G224p/1D17dmGVMaHJ+9jawonNzIZwYjOzUvGIzcxKx4nNzEqn2QcP2sGJzcyG8IjNzErFm6JmVjpObGZWOk5sVnr9R56QWz5pw5ziRhYtyi1+fJfiqbce/kv+TwfPPjv/BNx58y4r7GPr1o8V1hkLypDYCn8EL+kKSZslPZBZt0jSBkkr09sRrQ3TzEZLRHJUtJ5bp6pnxHYlcAlQ+dubCyLiK02PyMzaqgwjtsLEFhF3NuPiCmbWHcqQ2BqZj+1MSb9LN1X3qFVJ0gJJKySt6Ot7ooHuzGw0DCS2Js3H1hYjTWzfAF4LHAxsBL5aq2JELImIWRExq6dn7xF2Z2ajpQyJbURHRSNi08B9SZcBP2xaRGbWdp2ctOoxosQmaUpEDFwM8gPAA3n1zax7jInfikq6DphLcpmtXuA8YK6kg4EA1gKntTBG62D9k/YtrnThktziqy8rPsds0fjt+eWL8veqXHzxuMI+Pv/5/PLzzy9sohTKcPCgnqOiJ1VZ/a0WxGJmHWBMJDYzG3tGI7FJ2hO4HphJsuV3QkQ8XaXeS8D96eKjEfH+orZ9+T0zG2QUj4ouBG6LiAOB29Llap6PiIPTW2FSA4/YzKzCKB48OJpk/z3AVcAdwGeb0bATm5kNMsx9bD2SVmSWl0RE/tGiV0zOnF3xODC5Rr2d0z62AYsj4uaihp3YzGyIYSS2voiYVatQ0s+AfaoUnZNdiIiQVGsKl/0iYoOk1wC3S7o/Iv6YF5QTm5kN0uQrwR9Wq0zSpoFzYiVNATbXaGND+neNpDuAtwC5ic0HD8xskFE8eLAMmJ/enw98v7KCpD0k7ZTe7wHeDjxY1LBHbJZr4g9vyK9wc+HuDpg7N7d40Wc+U9hE/5/z/wcvXVrUwrrCPgrmwxwzRvE8tsXADZI+QvIGnQAgaRZwekR8FHg98E1J20kGYosjwonNzIZnYKLJ1vcTTwLzqqxfAXw0vf9L4E3DbduJzcwG8S8PzKx0nNjMrHSc2MysdJzYzKx0RuvgQSs5sZnZIB6xWUeb+PNbiiuddVZ++ezZ+eVFszMC/TMPKo6jQNEX7f7788vhNYV9jPe3AXBiM7MScmIzs9JxYjOzUnJiM7NSGRNXqTKzscWbomZWOk5sZlZKTmzWEhPXFk45BQtrXdQn9Yc/FLdx5ZW5xf0H/21xGw26+OLiOgsX5u/0Of74nXPLt26dn1tur/CIzcxKx4nNzErHR0XNrJQ8YjOzUinDpqivUmVmQ0Rsr+vWCEnHS1olaXt6AZda9Q6X9Iik1ZIKjpglnNjMrEIAL9V5a8gDwLHAnbUqSBoHfB14L3AQcJKkwulivClqZhUCeKH1vUQ8BCApr9ohwOqIWJPWXQocTcG1RT1iM7Mqttd5a7mpwPrMcm+6LpdHbC0ysff3+RUeeCC3ePMHP1jYx6t/+MPc8v53va+wjUZdeGFxnaK5KI85priNZ5/NPwHXk0Q208CmaF16JK3ILC+JiCUDC5J+BuxT5XHnRMSQK783S+HHQdJ04GpgMskzXhIRF0naE7gemAmsBU6IiKdbFaiZjZZhJba+iKi54z8iDmswmA3A9MzytHRdrno2RbcBn46Ig4DZwBnpzruFwG0RcSBwW7psZqUwKgcP6nEPcKCk/SXtCJwILCt6UGFii4iNEXFfen8L8BDJNu7RwFVptauAOjYozKzzjc5RUUkfkNQLHArcIunWdP2+kpYDRMQ24EzgVpLcc0NErCpqe1h7JiTNBN4C/BqYHBEb06LHSTZVqz1mAbAAYPr0GcPpzszaIoAXW99LxE3ATVXWPwYckVleDiwfTtt1HxWVtCvw78CnIuJPFYEEyasxREQsiYhZETGrp2fv4cRmZm0xauextUxdiU3SBJKkdm1EfC9dvUnSlLR8CrC5NSGa2egreWJTcvbct4CHIuJrmaJlwMAkV/OBlh26NbPR1P0jtnr2sb0dOAW4X9LKdN3ngMXADZI+AqwDTmhNiKNvYt+jueW9++1X3MY11+RXmD49t3jXrVW37AfpL6xRbPHixspPPrm4j97e/PJJk4rbsNE2KifftkxhYouIu4Bav3mY19xwzKz9hnUeW0fy+dpmVmF0fivaSk5sZlbBIzYzK6WS72Mzs7HGIzYzKyUnNjMrFR886DgTv/314kpFE4Sdf35u8bR77y3sov91by2Oo0HPPJNf/rrXFbexZUv+bwLXrZuQW97TU9yHdZvA+9jMrIS8KWpmpeKDB2ZWOk5sZlZK3sdmZqXio6JmVjreFDWzUnJiM7NS8XlsHaf/zDML60wsmNmw/8NnNBzHjTfmlxdc65jLLy/uY+bM/PKVK/PLkzbyT8C1sWh0NkUlHQ8sAl4PHBIRK2rUWwtsSYPalncd0wGlS2xm1gyjsin6AHAs8M066r4rIvrqbdiJzcwqjM5R0Yh4CCC5rEpz1X35PTMbKwb2sdVzo0fSisxtQYsC+omke+tt3yM2M6ui7k3Rvrx9XpJ+BuxTpeiciKj3ynZzImKDpFcDP5X0cETcmfcAJzYzq9C8gwcRcVgT2tiQ/t0s6SbgECA3sXlT1MwqdM51RSXtImm3gfvAe0gOOuRyYjOzCgMHD+q5jZykD0jqBQ4FbpF0a7p+X0nL02qTgbsk/Rb4DXBLRPy4qO3ybYqO0oWGixx3XGPl9SiaaNJs5Fp/gm5E3ATcVGX9Y8AR6f01wJuH23b5EpuZNci/FTWzUnJiM7NS8YjNzErJP4I3s1LZjieaNLMS8qaomZWK97GZWSl19z62wl8eSJou6eeSHpS0StIn0/WLJG2QtDK9HdH6cM2s9TrnJ1UjVc+IbRvw6Yi4L/3N1r2SfpqWXRARX2ldeGbWHp2btOpRmNgiYiOwMb2/RdJDwNRWB2Zm7dL9R0WH9SN4STOBtwC/TledKel3kq6QtEeTYzOztunuTdG6E5ukXYF/Bz4VEX8CvgG8FjiYZET31RqPWzAwu2Zf3xNNCNnMWmtYM+h2pLoSm6QJJEnt2oj4HkBEbIqIlyJiO3AZyeRvQ0TEkoiYFRGzenr2blbcZtZSJR+xKbnSwreAhyLia5n1UzLVPkAdk7+ZWTcYG0dF3w6cAtwvaeBKlZ8DTpJ0MMmrsBY4rSURmtkoC+DFdgfREEUUT8zYtM6kJ4B1mVU9QN3XCmwjx9lc3RBnN8QIQ+PcLyIa2ucj6cdpu/Xoi4jDG+mvFUY1sQ3pXFpRz1Wd281xNlc3xNkNMUL3xDnafM0DMysdJzYzK512J7Ylbe6/Xo6zubohzm6IEbonzlHV1n1sZmat0O4Rm5lZ0zmxmVnptC2xSTpc0iOSVkta2K44ikhaK+n+dM65Fe2OZ0A68cBmSQ9k1u0p6aeS/pD+bevEBDVi7Lh5/HLmHOy019NzI9apLfvYJI0Dfg+8G+gF7gFOiogHRz2YApLWArMioqNO1pT0DuA54OqIeGO67svAUxGxOP1nsUdEfLbDYlwEPNdJ8/ilPw+ckp1zEDgGOJXOej1rxXkCHfaatlu7RmyHAKsjYk1EvAAsBY5uUyxdKSLuBJ6qWH00cFV6/yqSD33b1Iix40TExoi4L72/BRiYc7DTXs9acVqFdiW2qcD6zHIvnfsGBfATSfdKWtDuYApMTicGBXgcmNzOYHJ07Dx+FXMOduzr6bkR8/ngQbE5EfFW4L3AGenmVceLZB9DJ57LU9c8fu1QZc7Bl3XS6znSuRHHknYltg3A9MzytHRdx4mIDenfzcBN1Jh3rkNsGphOKv27uc3xDFHvPH6jrdqcg3Tg69nI3IhjSbsS2z3AgZL2l7QjcCKwrE2x1CRpl3QnLZJ2Ad5DZ887twyYn96fD3y/jbFU1Ynz+NWac5AOez09N2L92vbLg/SQ9IXAOOCKiPhSWwLJIek1JKM0SOau+26nxCnpOmAuyfQym4DzgJuBG4AZJNNDnRARbdt5XyPGuSSbTC/P45fZj9UWkuYAvwDu55X5rj9Hsv+qk17PWnGeRIe9pu3mn1SZWen44IGZlY4Tm5mVjhObmZWOE5uZlY4Tm5mVjhObmZWOE5uZlc7/BxSKXb7opevBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show edge-detected activation map\n",
    "plt.imshow(activation_edge, cmap='seismic')\n",
    "plt.title('Edge detection activation map')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f93f220ba20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show blur activation map\n",
    "plt.imshow(activation_blur, cmap='seismic')\n",
    "plt.title('Gaussian blur activation map')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution in Keras\n",
    "Convolutional layers are very easy to add in Keras: just use the appropriate layer (usually Conv1D or Conv2D) from [its set of convolutional layers](https://keras.io/layers/convolutional/).\n",
    "It has a [set of pooling layers too](https://keras.io/layers/pooling/), of which MaxPooling1D and MaxPooling2D are the most common.\n",
    "To transition from convolutional to dense layers, use keras.layers.Flatten.\n",
    "\n",
    "The only slightly tricky part of making many common traditional CNNs in Keras is making sure the shapes check out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Image CNN with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (1797, 8, 8, 1)\n",
      "Target shape: (1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load data\n",
    "dataset = load_digits()\n",
    "\n",
    "x_all = dataset.data\n",
    "y_all = dataset.target\n",
    "\n",
    "# Shuffle some features and targets together\n",
    "together = np.concatenate([x_all, np.expand_dims(y_all, axis=1)], \n",
    "                          axis=1)\n",
    "np.random.shuffle(together)\n",
    "x_all = together[:, :-1]\n",
    "y_all = together[:, -1]\n",
    "\n",
    "# Split data into train and test sets\n",
    "n_points = x_all.shape[0]\n",
    "n_features = x_all.shape[1]\n",
    "x_all = np.reshape(x_all, (n_points, 8, 8))\n",
    "x_all = np.expand_dims(x_all, axis=-1)\n",
    "n_train = int(n_points * 0.7)\n",
    "n_test = n_points - n_train\n",
    "\n",
    "print('Input shape:', x_all.shape)\n",
    "print('Target shape:', y_all.shape)\n",
    "\n",
    "x_train, x_test = np.split(x_all, [n_train], axis=0)\n",
    "y_train, y_test = np.split(y_all, [n_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label:6.0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0, :, :, 0])\n",
    "plt.title('Label:' + str(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# First, two 2x2, 16-filter convolutional layers\n",
    "model.add(Conv2D(filters=16, kernel_size=2,\n",
    "                 padding='same', activation='relu',\n",
    "                 input_shape=(8, 8, 1)))\n",
    "model.add(Conv2D(16, 2, padding='same', \n",
    "                 activation='relu'))\n",
    "\n",
    "# Then, a 2x2 max pooling\n",
    "model.add(MaxPool2D(pool_size=2))\n",
    "\n",
    "\n",
    "# Two 2x2, 32-filter convolutional layers\n",
    "model.add(Conv2D(32, 2, padding='same', \n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(32, 2, padding='same', \n",
    "                 activation='relu'))\n",
    "\n",
    "# Flatten the image into a vector\n",
    "model.add(Flatten())\n",
    "\n",
    "# A single dense layer with 300 units\n",
    "model.add(Dense(300, activation='relu'))\n",
    "\n",
    "# Output layer, for 10-class classification: \n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile with an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 8, 8, 16)          80        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 16)          1040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 32)          2080      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 32)          4128      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               153900    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 164,238\n",
      "Trainable params: 164,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "optimizer = SGD(lr=1e-3, momentum=0.9)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1257 samples, validate on 540 samples\n",
      "Epoch 1/50\n",
      "1257/1257 [==============================] - 0s 251us/step - loss: 2.2419 - categorical_accuracy: 0.2379 - val_loss: 2.0189 - val_categorical_accuracy: 0.5093\n",
      "Epoch 2/50\n",
      "1257/1257 [==============================] - 0s 153us/step - loss: 1.6420 - categorical_accuracy: 0.6285 - val_loss: 1.1155 - val_categorical_accuracy: 0.7074\n",
      "Epoch 3/50\n",
      "1257/1257 [==============================] - 0s 138us/step - loss: 0.7711 - categorical_accuracy: 0.7717 - val_loss: 0.6062 - val_categorical_accuracy: 0.7778\n",
      "Epoch 4/50\n",
      "1257/1257 [==============================] - 0s 150us/step - loss: 0.4029 - categorical_accuracy: 0.8807 - val_loss: 0.3146 - val_categorical_accuracy: 0.9074\n",
      "Epoch 5/50\n",
      "1257/1257 [==============================] - 0s 135us/step - loss: 0.2975 - categorical_accuracy: 0.9014 - val_loss: 0.3609 - val_categorical_accuracy: 0.8759\n",
      "Epoch 6/50\n",
      "1257/1257 [==============================] - 0s 146us/step - loss: 0.2228 - categorical_accuracy: 0.9260 - val_loss: 0.2173 - val_categorical_accuracy: 0.9333\n",
      "Epoch 7/50\n",
      "1257/1257 [==============================] - 0s 147us/step - loss: 0.1748 - categorical_accuracy: 0.9459 - val_loss: 0.1749 - val_categorical_accuracy: 0.9278\n",
      "Epoch 8/50\n",
      "1257/1257 [==============================] - 0s 148us/step - loss: 0.1346 - categorical_accuracy: 0.9586 - val_loss: 0.1610 - val_categorical_accuracy: 0.9463\n",
      "Epoch 9/50\n",
      "1257/1257 [==============================] - 0s 151us/step - loss: 0.1398 - categorical_accuracy: 0.9515 - val_loss: 0.2025 - val_categorical_accuracy: 0.9278\n",
      "Epoch 10/50\n",
      "1257/1257 [==============================] - 0s 139us/step - loss: 0.1133 - categorical_accuracy: 0.9626 - val_loss: 0.1458 - val_categorical_accuracy: 0.9519\n",
      "Epoch 11/50\n",
      "1257/1257 [==============================] - 0s 172us/step - loss: 0.0811 - categorical_accuracy: 0.9769 - val_loss: 0.1751 - val_categorical_accuracy: 0.9389\n",
      "Epoch 12/50\n",
      "1257/1257 [==============================] - 0s 158us/step - loss: 0.1058 - categorical_accuracy: 0.9650 - val_loss: 0.1520 - val_categorical_accuracy: 0.9537\n",
      "Epoch 13/50\n",
      "1257/1257 [==============================] - 0s 157us/step - loss: 0.0664 - categorical_accuracy: 0.9833 - val_loss: 0.1014 - val_categorical_accuracy: 0.9630\n",
      "Epoch 14/50\n",
      "1257/1257 [==============================] - 0s 140us/step - loss: 0.0612 - categorical_accuracy: 0.9801 - val_loss: 0.1404 - val_categorical_accuracy: 0.9426\n",
      "Epoch 15/50\n",
      "1257/1257 [==============================] - 0s 159us/step - loss: 0.0613 - categorical_accuracy: 0.9801 - val_loss: 0.1505 - val_categorical_accuracy: 0.9444\n",
      "Epoch 16/50\n",
      "1257/1257 [==============================] - 0s 161us/step - loss: 0.0727 - categorical_accuracy: 0.9793 - val_loss: 0.3165 - val_categorical_accuracy: 0.8981\n",
      "Epoch 17/50\n",
      "1257/1257 [==============================] - 0s 162us/step - loss: 0.0666 - categorical_accuracy: 0.9809 - val_loss: 0.1062 - val_categorical_accuracy: 0.9556\n",
      "Epoch 18/50\n",
      "1257/1257 [==============================] - 0s 175us/step - loss: 0.0407 - categorical_accuracy: 0.9881 - val_loss: 0.1255 - val_categorical_accuracy: 0.9593\n",
      "Epoch 19/50\n",
      "1257/1257 [==============================] - 0s 202us/step - loss: 0.0357 - categorical_accuracy: 0.9928 - val_loss: 0.0943 - val_categorical_accuracy: 0.9648\n",
      "Epoch 20/50\n",
      "1257/1257 [==============================] - 0s 198us/step - loss: 0.0243 - categorical_accuracy: 0.9960 - val_loss: 0.0809 - val_categorical_accuracy: 0.9648\n",
      "Epoch 21/50\n",
      "1257/1257 [==============================] - 0s 196us/step - loss: 0.0294 - categorical_accuracy: 0.9920 - val_loss: 0.0844 - val_categorical_accuracy: 0.9685\n",
      "Epoch 22/50\n",
      "1257/1257 [==============================] - 0s 189us/step - loss: 0.0219 - categorical_accuracy: 0.9960 - val_loss: 0.0823 - val_categorical_accuracy: 0.9685\n",
      "Epoch 23/50\n",
      "1257/1257 [==============================] - 0s 182us/step - loss: 0.0183 - categorical_accuracy: 0.9976 - val_loss: 0.0754 - val_categorical_accuracy: 0.9722\n",
      "Epoch 24/50\n",
      "1257/1257 [==============================] - 0s 195us/step - loss: 0.0169 - categorical_accuracy: 0.9968 - val_loss: 0.0831 - val_categorical_accuracy: 0.9648\n",
      "Epoch 25/50\n",
      "1257/1257 [==============================] - 0s 172us/step - loss: 0.0192 - categorical_accuracy: 0.9968 - val_loss: 0.0893 - val_categorical_accuracy: 0.9648\n",
      "Epoch 26/50\n",
      "1257/1257 [==============================] - 0s 190us/step - loss: 0.0158 - categorical_accuracy: 0.9992 - val_loss: 0.0715 - val_categorical_accuracy: 0.9778\n",
      "Epoch 27/50\n",
      "1257/1257 [==============================] - 0s 172us/step - loss: 0.0125 - categorical_accuracy: 0.9976 - val_loss: 0.0885 - val_categorical_accuracy: 0.9704\n",
      "Epoch 28/50\n",
      "1257/1257 [==============================] - 0s 167us/step - loss: 0.0105 - categorical_accuracy: 0.9992 - val_loss: 0.0636 - val_categorical_accuracy: 0.9778\n",
      "Epoch 29/50\n",
      "1257/1257 [==============================] - 0s 168us/step - loss: 0.0090 - categorical_accuracy: 1.0000 - val_loss: 0.0731 - val_categorical_accuracy: 0.9704\n",
      "Epoch 30/50\n",
      "1257/1257 [==============================] - 0s 167us/step - loss: 0.0096 - categorical_accuracy: 0.9992 - val_loss: 0.0946 - val_categorical_accuracy: 0.9630\n",
      "Epoch 31/50\n",
      "1257/1257 [==============================] - 0s 168us/step - loss: 0.0088 - categorical_accuracy: 1.0000 - val_loss: 0.0795 - val_categorical_accuracy: 0.9759\n",
      "Epoch 32/50\n",
      "1257/1257 [==============================] - 0s 181us/step - loss: 0.0078 - categorical_accuracy: 0.9992 - val_loss: 0.0621 - val_categorical_accuracy: 0.9722\n",
      "Epoch 33/50\n",
      "1257/1257 [==============================] - 0s 173us/step - loss: 0.0076 - categorical_accuracy: 0.9992 - val_loss: 0.0801 - val_categorical_accuracy: 0.9685\n",
      "Epoch 34/50\n",
      "1257/1257 [==============================] - 0s 202us/step - loss: 0.0083 - categorical_accuracy: 0.9992 - val_loss: 0.0630 - val_categorical_accuracy: 0.9722\n",
      "Epoch 35/50\n",
      "1257/1257 [==============================] - 0s 169us/step - loss: 0.0062 - categorical_accuracy: 1.0000 - val_loss: 0.0810 - val_categorical_accuracy: 0.9648\n",
      "Epoch 36/50\n",
      "1257/1257 [==============================] - 0s 185us/step - loss: 0.0076 - categorical_accuracy: 0.9992 - val_loss: 0.0760 - val_categorical_accuracy: 0.9667\n",
      "Epoch 37/50\n",
      "1257/1257 [==============================] - 0s 166us/step - loss: 0.0052 - categorical_accuracy: 1.0000 - val_loss: 0.0680 - val_categorical_accuracy: 0.9759\n",
      "Epoch 38/50\n",
      "1257/1257 [==============================] - 0s 160us/step - loss: 0.0049 - categorical_accuracy: 1.0000 - val_loss: 0.0630 - val_categorical_accuracy: 0.9722\n",
      "Epoch 39/50\n",
      "1257/1257 [==============================] - 0s 154us/step - loss: 0.0047 - categorical_accuracy: 1.0000 - val_loss: 0.0685 - val_categorical_accuracy: 0.9685\n",
      "Epoch 40/50\n",
      "1257/1257 [==============================] - 0s 162us/step - loss: 0.0045 - categorical_accuracy: 1.0000 - val_loss: 0.0745 - val_categorical_accuracy: 0.9704\n",
      "Epoch 41/50\n",
      "1257/1257 [==============================] - 0s 162us/step - loss: 0.0050 - categorical_accuracy: 1.0000 - val_loss: 0.0633 - val_categorical_accuracy: 0.9778\n",
      "Epoch 42/50\n",
      "1257/1257 [==============================] - 0s 172us/step - loss: 0.0046 - categorical_accuracy: 1.0000 - val_loss: 0.0629 - val_categorical_accuracy: 0.9759\n",
      "Epoch 43/50\n",
      "1257/1257 [==============================] - 0s 201us/step - loss: 0.0032 - categorical_accuracy: 1.0000 - val_loss: 0.0694 - val_categorical_accuracy: 0.9685\n",
      "Epoch 44/50\n",
      "1257/1257 [==============================] - 0s 187us/step - loss: 0.0037 - categorical_accuracy: 1.0000 - val_loss: 0.0622 - val_categorical_accuracy: 0.9759\n",
      "Epoch 45/50\n",
      "1257/1257 [==============================] - 0s 173us/step - loss: 0.0046 - categorical_accuracy: 1.0000 - val_loss: 0.0651 - val_categorical_accuracy: 0.9722\n",
      "Epoch 46/50\n",
      "1257/1257 [==============================] - 0s 179us/step - loss: 0.0033 - categorical_accuracy: 1.0000 - val_loss: 0.0665 - val_categorical_accuracy: 0.9759\n",
      "Epoch 47/50\n",
      "1257/1257 [==============================] - 0s 168us/step - loss: 0.0031 - categorical_accuracy: 1.0000 - val_loss: 0.0697 - val_categorical_accuracy: 0.9667\n",
      "Epoch 48/50\n",
      "1257/1257 [==============================] - 0s 187us/step - loss: 0.0030 - categorical_accuracy: 1.0000 - val_loss: 0.0663 - val_categorical_accuracy: 0.9741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "1257/1257 [==============================] - 0s 168us/step - loss: 0.0028 - categorical_accuracy: 1.0000 - val_loss: 0.0678 - val_categorical_accuracy: 0.9722\n",
      "Epoch 50/50\n",
      "1257/1257 [==============================] - 0s 154us/step - loss: 0.0026 - categorical_accuracy: 1.0000 - val_loss: 0.0651 - val_categorical_accuracy: 0.9741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f93aa7945c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to one-hot encode the targets\n",
    "y_train_onehot = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "model.fit(x_train, y_train_onehot,\n",
    "          epochs=50, batch_size=32,\n",
    "          validation_data=(x_test, y_test_onehot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities: [[4.0648729e-09 1.3662812e-01 8.6336970e-01 1.4656873e-06 1.8166010e-11\n",
      "  7.2686364e-09 6.1338049e-08 1.2296468e-12 5.7196934e-07 3.8771770e-08]]\n",
      "Predicted class: 2\n",
      "True class label: 2.0\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict([[x_test[0]]], batch_size=1)\n",
    "\n",
    "print('Predicted probabilities:', pred)\n",
    "print('Predicted class:', np.argmax(pred))\n",
    "print('True class label:', y_test[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
